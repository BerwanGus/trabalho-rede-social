# -*- coding: utf-8 -*-
"""Titanic Segunda.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17fM-YX2SXn_UTq204G6-i4ymaPgq0Noy

# Parte 1
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

url = 'https://learnenough.s3.amazonaws.com/titanic.csv'
titanic = pd.read_csv(url, index_col='Name')
titanic.head()

titanic.iloc[0]['Survived']
titanic.iloc[1]['Survived']
titanic['Survived'].mean()
titanic.info()

titanic['Pclass'].unique()
survival_rates = titanic.groupby('Pclass')['Survived'].mean()
survival_rates.plot.bar()
plt.show()

titanic['Sex'].unique()

titanic['Sex'].unique()
survival_rates = titanic.groupby('Sex')['Survived'].mean()
survival_rates.plot.bar()
plt.show()

print(titanic['Age'].min(), titanic['Age'].max())
print((titanic['Age'].max() - titanic['Age'].min()) / 7 )

ageMask = titanic['Age'].notna()
valid_ages = titanic[ageMask]
# valid_ages.head()
sorted_by_age = valid_ages.sort_values(by='Age')
sorted_by_age.head()

sorted_by_age['Age Range'] = pd.cut(sorted_by_age['Age'], 7)
# sorted_by_age['Age Range']
survival_rates = sorted_by_age.groupby('Age Range')['Survived'].mean()
survival_rates.plot.bar()
plt.show()

titanic[titanic['Sex'] == 'male']['Age'].mean()
titanic[titanic['Sex'] == 'female']['Age'].mean()

# Filtra os passageiros dada uma coluna (sexo)
male_passengers = titanic[titanic['Sex'] == 'male']
female_passengers = titanic[titanic['Sex'] == 'female']

# Para cada tabela (M/F) filtrar novamente apenas pelos que tem idade válida
valid_male_ages = male_passengers[male_passengers['Age'].notna()]
valid_female_ages = female_passengers[female_passengers['Age'].notna()]

# Ordena a tabela baseado em uma coluna especifica, no caso idade (Age)
m_sorted_by_age = valid_male_ages.sort_values(by='Age')
f_sorted_by_age = valid_female_ages.sort_values(by='Age')

# Divide ela em 7 faixas etárias
m_sorted_by_age['Age Range'] = pd.cut(m_sorted_by_age['Age'], 7)
f_sorted_by_age['Age Range'] = pd.cut(f_sorted_by_age['Age'], 7)

# Calcula a taxa de sobrevivência para cada uma das faixas etárias
m_survival_rates = m_sorted_by_age.groupby('Age Range')['Survived'].mean()
f_survival_rates = f_sorted_by_age.groupby('Age Range')['Survived'].mean()

m_survival_rates.plot.bar()
plt.show()

f_survival_rates.plot.bar()
plt.show()

"""# Parte 2"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import Perceptron
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

url = 'https://learnenough.s3.amazonaws.com/titanic.csv'
titanic = pd.read_csv(url)
# titanic.head()

columns_to_drop = ['Name', 'PassengerId', 'Cabin', 'Embarked',
                   'SibSp', 'Parch', 'Ticket', 'Fare']

for column in columns_to_drop:
  titanic = titanic.drop(column, axis=1)

for column in ['Age', 'Sex', 'Pclass']:
  titanic = titanic[titanic[column].notna()]

sex_int = {'male': 0, 'female': 1}
titanic['Sex'] = titanic['Sex'].map(sex_int)

titanic.head()

X = titanic.drop('Survived', axis=1)
y = titanic['Survived']

print(X.head())
print('-'*40)
print(y.head())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

clf_dt = DecisionTreeClassifier()
clf_dt.fit(X_train, y_train)
acc_dt = clf_dt.score(X_test, y_test)
print(acc_dt)

clf_nb = GaussianNB()
clf_nb.fit(X_train, y_train)
acc_nb = clf_nb.score(X_test, y_test)
print(acc_nb)

clf_p = Perceptron()
clf_p.fit(X_train, y_train)
acc_p = clf_p.score(X_test, y_test)
print(acc_p)

clf_rf = RandomForestClassifier()
clf_rf.fit(X_train, y_train)
acc_rf = clf_rf.score(X_test, y_test)
print(acc_rf)

print('-'*30)
print(f'DT: {acc_dt:.6f}')
print(f'RF: {acc_rf:.6}')
print(f'NB: {acc_nb:.4}')
print(f'Pe: {acc_p:.4}')
print('-'*30)

print(clf_rf.feature_importances_)
print(X_train.columns)

print(clf_dt.feature_importances_)
print(X_train.columns)

fig, ax = plt.subplots()
ax.bar(X_train.columns, clf_rf.feature_importances_)
plt.show()

from sklearn.model_selection import cross_val_score

clf_rf = RandomForestClassifier(random_state=1)
scores = cross_val_score(clf_rf, X_train, y_train)
print(f'Por fold: {scores}')
print(f'Media das folds: {scores.mean()}')

"""
Alterar estes dois parametros

n_estimators = ?

max_depth = ?



Ver os resultados, e se a ordem de importancia de features tbm muda, ou não"""

clf_rf = RandomForestClassifier(max_depth=3, random_state=1, n_estimators=200)
clf_rf.fit(X_train, y_train)
acc_rf = clf_rf.score(X_test, y_test)
print(acc_rf)
print(clf_rf.feature_importances_)

clf_dt = DecisionTreeClassifier(max_depth=3, random_state=1)
clf_dt.fit(X_train, y_train)
acc_dt = clf_dt.score(X_test, y_test)
print(acc_dt)
print(clf_dt.feature_importances_)